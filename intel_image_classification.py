# -*- coding: utf-8 -*-
"""Intel-Image-Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16TzzVg13fgInnLHRb-ZznzmDfPW8GKdY
"""

# Commented out IPython magic to ensure Python compatibility.
import os
import pathlib
import time
import numpy as np
import matplotlib.pyplot as plt
import torch
from torch import nn, optim
import torch.nn.functional as F
from torchvision import datasets, transforms
from torch.utils.data.sampler import SubsetRandomSampler

# %matplotlib inline

# check if cuda is available
train_on_gpu = torch.cuda.is_available()

if not train_on_gpu:
  print("Training on CPU")
else:
  print("Training on GPU")

train_data_path = "drive/My Drive/dataset/intel/seg_train/seg_train"
test_data_path = "drive/My Drive/dataset/intel/seg_test/seg_test"
pred_path = "drive/My Drive/dataset/intel/seg_pred/seg_pred"

data_transform = transforms.Compose([transforms.Resize((150,150)),
                                     transforms.ToTensor(),
                                     transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])])

train_data = datasets.ImageFolder(train_data_path , transform = data_transform)

test_data = datasets.ImageFolder(test_data_path, transform  = data_transform)

val_size = 0.2
batch_size = 128
num_workers = 0


# Create validation set
num_train = len(train_data)
indices = list(range(num_train))
np.random.shuffle(indices)
split = int(np.floor(val_size*num_train))
train_idx, valid_idx = indices[split:], indices[:split]

# Define samplers for obtaining training and validation batches
train_sampler = SubsetRandomSampler(train_idx)
valid_sampler = SubsetRandomSampler(valid_idx)


# Create dataloaders
train_loader = torch.utils.data.DataLoader(train_data, batch_size= batch_size, 
                                           sampler = train_sampler,
                                           num_workers = num_workers)


val_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size,
                                         sampler = valid_sampler,
                                         num_workers = num_workers)

test_loader = torch.utils.data.DataLoader(test_data, batch_size = batch_size)

class Classifier(nn.Module):

  def __init__(self):
    super(Classifier, self).__init__()

    self.conv1 = nn.Conv2d(in_channels= 3, out_channels= 16, kernel_size = 3, padding = 1)
    self.conv2 = nn.Conv2d(in_channels= 16, out_channels= 32, kernel_size= 3, padding = 1)
    self.conv3 = nn.Conv2d(in_channels= 32, out_channels= 64, kernel_size = 3, padding = 1)
    self.conv4 = nn.Conv2d(in_channels = 64, out_channels= 128, kernel_size= 3, padding = 1)
    self.conv5 = nn.Conv2d(in_channels= 128, out_channels= 256, kernel_size= 3, padding = 1)

    self.pool = nn.MaxPool2d(kernel_size= 2, stride= 2)
    self.dropout = nn.Dropout(p = 0.2)

    self.fc1 = nn.Linear(in_features= 4*4*256 , out_features= 1024 )
    self.fc2 = nn.Linear(in_features= 1024 , out_features= 512 )
    self.fc3 = nn.Linear(in_features= 512, out_features= 6)

  
  def forward(self, x):

    x = self.pool(F.relu(self.conv1(x)))
    x = self.pool(F.relu(self.conv2(x)))
    x = self.dropout(x)
    x = self.pool(F.relu(self.conv3(x)))
    x = self.pool(F.relu(self.conv4(x)))
    x = self.dropout(x)
    x = self.pool(F.relu(self.conv5(x)))

    x = x.view(x.size(0), -1)

    x = F.relu(self.fc1(x))
    x = self.dropout(x)
    x = F.relu(self.fc2(x))
    x = self.dropout(x)
    x = F.relu(self.fc3(x))

    return x

model = Classifier()
print(model)

if train_on_gpu:
  model.cuda()

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr = 0.001)

n_epochs = 30
val_loss_min = np.Inf
step = 0
training_loss = []
validation_loss = []

for e in range(n_epochs):
  train_loss = 0
  val_loss = 0

  start_time = time.time()
  total_train_loss = 0

#-----------------
# TRAINING MODEL  
#-----------------

  model.train()
  for img, label in train_loader:
    # move tensor to gpu
    if train_on_gpu:
      img, label = img.cuda(), label.cuda()


    optimizer.zero_grad()
    output = model(img)
    loss = criterion(output, label)
    loss.backward()
    optimizer.step()

    train_loss += loss.item()*img.size(0)

    if step % 10 == 0:
      print("Step {} is in progress...".format(step))
  
    step += 1


#-------------
# Validation
#-------------

  model.eval()
  for img, label in val_loader:

    if train_on_gpu:
      img, label = img.cuda(), label.cuda()

    output = model(img)
    loss = criterion(output, label)
    
    val_loss += loss.item()*img.size(0)

  train_loss = train_loss / len(train_loader.sampler)
  val_loss = val_loss / len(val_loader.sampler)
  
  # append loss 
  training_loss.append(train_loss)
  validation_loss.append(val_loss)

  print("Epoch: {}  \tTraining Loss: {:.4f}  \tValidation Loss: {:.4f}  \ttook: {:.2f}s".format(e, train_loss, val_loss, time.time() - start_time))

  if val_loss <= val_loss_min:
    print("Validation Loss Decreased from: {:.4f} -----> {:.4f}  \tSaving Model.... ".format(val_loss_min, val_loss))
    torch.save(model.state_dict(), "drive/My Drive/dataset/intel/model.pt")
    val_loss_min = val_loss

  start_time = time.time()

model.load_state_dict(torch.load("drive/My Drive/dataset/intel/model.pt"))

# Get the classes
import pathlib
root = pathlib.Path('drive/My Drive/dataset/intel/seg_train/seg_train')
classes = sorted([j.name.split('/')[-1] for j in root.iterdir()])
print(classes)

batch_size = 128

pred_transform = transforms.Compose([transforms.Resize((150,150)),
                                     transforms.ToTensor()])


load_data = datasets.ImageFolder('drive/My Drive/dataset/intel/seg_pred',transform = pred_transform)

data = torch.utils.data.DataLoader(load_data , batch_size= batch_size)

X_pred, y_pred = next(iter(data))
print(X_pred.size())

if train_on_gpu:
      X_pred, y_pred = X_pred.cuda(), y_pred.cuda()


output = model(X_pred)
_, pred = torch.max(output , 1)

X_pred, y_pred = X_pred.cpu(), y_pred.cpu()

print(pred)

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
# %matplotlib inline

def imshow(img):
  '''
  Function to un-normalize and display an image
  '''
  img = img/2 + 0.5 # un-normalize
  plt.imshow(np.transpose(img, (1, 2, 0))) # convert from tensor image

# Visualize predicted labels
fig = plt.figure(figsize = (25,4))
for idx in np.arange(20):
  ax = fig.add_subplot(2, 20/2, idx + 1, xticks = [], yticks = [])
  imshow(X_pred[idx])
  ax.set_title('{}'.format(classes[pred[idx]]))

print(classes)
print(pred)

plt.plot(training_loss, label = 'Training loss')
plt.plot(validation_loss, label = 'Validation loss')
plt.legend(frameon = False)
plt.show

test_loss = 0
correct_cls = list(0. for i in range(len(classes)))
total_cls = list(0. for i in range(len(classes)))

model.eval()
for img, label in test_loader:
  if train_on_gpu:
    img , label = img.cuda(), label.cuda()

  output = model(img)
  loss = criterion(output, label)

  test_loss += loss.item()*img.size(0)
  _, pred = torch.max(output, 1)

  correct_pred = pred.eq(label.view_as(pred))
  correct = np.sequeeze(correct_pred.numpy()) if not train_on_gpu else np.squeeze(correct_pred.cpu().numpy())

  for i in range(10):
    target = label.data[i]
    correct_cls[target] += correct[i].item()
    total_cls[target] += 1
  

test_loss = test_loss / len(test_loader.dataset)
print("Test Loss: {:.4f}".format(test_loss))

for i in range(6):
  if total_cls[i] > 0:
    print('Test accuracy of %5s: %2d%% (%2d/%2d)' % (
          classes[i], 100*correct_cls[i] / total_cls[i], 
          np.sum(correct_cls[i]), np.sum(total_cls[i])))
  else:
    print('Test accuracy of %5s: N/A (no training examples)' % (classes[i]))

print('\nTest accuracy (Overall): %2d%% (%2d/%2d)' % (
    100.*np.sum(correct_cls)/ np.sum(total_cls),
    np.sum(correct_cls), np.sum(total_cls)))

